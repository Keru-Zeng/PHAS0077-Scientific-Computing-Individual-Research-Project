{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd146f8",
   "metadata": {},
   "source": [
    "test the build-in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37c12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful libraries\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "import pims\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8e5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10 # the higher the better\n",
    "IMG_WIDTH = 128 # for faster computing on kaggle\n",
    "IMG_HEIGHT = 128 # for faster computing on kaggle\n",
    "IMG_CHANNELS = 3 \n",
    "TEST_PATH='./test_set/'# our project\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "n_num=num(dirname='tifs - unanalysed/')\n",
    "#build our test set\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "X_test = np.zeros((n_num, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "#just to ensure that len of X_test is equal to len of sizes_test\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "n=0\n",
    "for id_ in tqdm(test_ids, total=len(test_ids)):\n",
    "    path = TEST_PATH + id_+'/images/'\n",
    "    dir_3=os.listdir(path)\n",
    "    k=len(dir_3)\n",
    "    for i in range(0,k): \n",
    "        img = imread(path +dir_3[i])[:,:,:IMG_CHANNELS] # look for all pictures with name Series001\n",
    "        sizes_test.append([img.shape[0], img.shape[1]])# append sizes of figures i.e. 256*256 pixel: [256,256]\n",
    "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "        X_test[n]=img\n",
    "        n+=1\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a82bb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:28<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for id_ in tqdm(test_ids, total=len(test_ids)):\n",
    "    path = TEST_PATH + id_+'/images/'\n",
    "    dir_3=os.listdir(path)\n",
    "    k=len(dir_3)\n",
    "    for i in range(0,k):   \n",
    "        image = imread(path +dir_3[i])[:,:,:3]# load the pictures\n",
    "        image = rgb2gray(image) #convert to greyscale after loading\n",
    "        thresh = threshold_otsu(image) # perform automatic thresholding\n",
    "        bw = closing(image >thresh,square(3)) #convert 0，1 to bool\n",
    "        # remove artifacts connected to image border\n",
    "        cleared = clear_border(bw)\n",
    "        # label image regions\n",
    "        label_image = label(cleared)\n",
    "        # to make the background transparent, pass the value of `bg_label`,\n",
    "        # and leave `bg_color` as `None` and `kind` as `overlay`\n",
    "        image_label_overlay = label2rgb(label_image, image=image, bg_label=0)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.imshow(image_label_overlay)\n",
    "        for region in regionprops(label_image):\n",
    "            # take regions with large enough areas\n",
    "            if region.area >= 150:\n",
    "                # draw rectangle around segmented coins\n",
    "                minr, minc, maxr, maxc = region.bbox\n",
    "                rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr, fill=False, edgecolor='red', linewidth=2)\n",
    "                ax.add_patch(rect)\n",
    "        ax.set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        figure_save_path ='label_set/'+id_\n",
    "        if not os.path.exists(figure_save_path):# if directory not exist, create it\n",
    "            os.makedirs(figure_save_path)   \n",
    "        plt.savefig(os.path.join(figure_save_path , '{}'.format(dir_3[i])),bbox_inches='tight', pad_inches = -0.1)\n",
    "        plt.close()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe6ce7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 297ms/step\n"
     ]
    }
   ],
   "source": [
    "#load the model and use it to make predicted results\n",
    "model = load_model('model.h5', custom_objects={'mean_iou': tf.keras.metrics.MeanIoU(num_classes=2)})\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "#Threshold predictions\n",
    "preds_test_t = (preds_test > 0.8).astype(np.uint8)\n",
    "\n",
    "#Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a48aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '1.2%_1Hour_A-Tubulin.lif - Series001.tif', 1: '1.2%_1Hour_A-Tubulin.lif - Series002.tif', 2: '1.2%_1Hour_A-Tubulin.lif - Series003.tif', 3: '1.2%_1Hour_A-Tubulin.lif - Series004.tif', 4: '1.2%_1Hour_A-Tubulin.lif - Series005.tif', 5: '1.2%_1Hour_A-Tubulin.lif - Series006.tif', 6: '1.2%_1Hour_B-Actin.lif - Series001.tif', 7: '1.2%_1Hour_B-Actin.lif - Series002.tif', 8: '1.2%_1Hour_B-Actin.lif - Series003.tif', 9: '1.2%_1Hour_B-Actin.lif - Series004.tif', 10: '1.2%_1Hour_B-Actin.lif - Series005.tif', 11: '1.2%_1Hour_B-Actin.lif - Series006.tif', 12: '1.2%_1Hour_Caveolin 1.lif - Series001.tif', 13: '1.2%_1Hour_Caveolin 1.lif - Series002.tif', 14: '1.2%_1Hour_Caveolin 1.lif - Series003.tif', 15: '1.2%_1Hour_Caveolin 1.lif - Series004.tif', 16: '1.2%_1Hour_Caveolin 1.lif - Series005.tif', 17: '1.2%_1Hour_Caveolin 1.lif - Series006.tif', 18: '1.2%_1Hour_Clathrin.lif - Series001.tif', 19: '1.2%_1Hour_Clathrin.lif - Series002.tif', 20: '1.2%_1Hour_Clathrin.lif - Series003.tif', 21: '1.2%_1Hour_Clathrin.lif - Series004.tif', 22: '1.2%_1Hour_Clathrin.lif - Series005.tif', 23: '1.2%_1Hour_Dynamin.lif - Series001.tif', 24: '1.2%_1Hour_Dynamin.lif - Series002.tif', 25: '1.2%_1Hour_Dynamin.lif - Series003.tif', 26: '1.2%_1Hour_Dynamin.lif - Series004.tif', 27: '1.2%_1Hour_Dynamin.lif - Series005.tif', 28: '1.2%_1Hour_Dynamin.lif - Series006.tif', 29: '1.2%_1Hour_Dynein.lif - Series001.tif', 30: '1.2%_1Hour_Dynein.lif - Series002.tif', 31: '1.2%_1Hour_Dynein.lif - Series003.tif', 32: '1.2%_1Hour_Dynein.lif - Series004.tif', 33: '1.2%_1Hour_Dynein.lif - Series005.tif', 34: '1.2%_1Hour_Dynein.lif - Series006.tif', 35: '1.2%_1Hour_EEA-1.lif - Series001.tif', 36: '1.2%_1Hour_EEA-1.lif - Series002.tif', 37: '1.2%_1Hour_EEA-1.lif - Series003.tif', 38: '1.2%_1Hour_EEA-1.lif - Series004.tif', 39: '1.2%_1Hour_EEA-1.lif - Series005.tif', 40: '1.2%_1Hour_EEA-1.lif - Series006.tif', 41: '1.2%_1Hour_Kinesin.lif - Series001.tif', 42: '1.2%_1Hour_Kinesin.lif - Series002.tif', 43: '1.2%_1Hour_Kinesin.lif - Series003.tif', 44: '1.2%_1Hour_Kinesin.lif - Series004.tif', 45: '1.2%_1Hour_Kinesin.lif - Series005.tif', 46: '1.2%_1Hour_Kinesin.lif - Series006.tif', 47: '1.2%_1Hour_LAMP-1.lif - Series001.tif', 48: '1.2%_1Hour_LAMP-1.lif - Series002.tif', 49: '1.2%_1Hour_LAMP-1.lif - Series003.tif', 50: '1.2%_1Hour_LAMP-1.lif - Series004.tif', 51: '1.2%_1Hour_LAMP-1.lif - Series005.tif', 52: '1.2%_1Hour_LAMP-1.lif - Series006.tif', 53: '1.2%_1Hour_Myosin.lif - Series001.tif', 54: '1.2%_1Hour_Myosin.lif - Series002.tif', 55: '1.2%_1Hour_Myosin.lif - Series003.tif', 56: '1.2%_1Hour_Myosin.lif - Series004.tif', 57: '1.2%_1Hour_Myosin.lif - Series005.tif', 58: '1.2%_1Hour_Myosin.lif - Series006.tif', 59: '1.2%_1Hour_Rab11.lif - Series001.tif', 60: '1.2%_1Hour_Rab11.lif - Series002.tif', 61: '1.2%_1Hour_Rab11.lif - Series003.tif', 62: '1.2%_1Hour_Rab11.lif - Series004.tif', 63: '1.2%_1Hour_Rab11.lif - Series005.tif', 64: '1.2%_1Hour_Rab11.lif - Series006.tif', 65: '1.2%_1Hour_Rab5.lif - Series001.tif', 66: '1.2%_1Hour_Rab5.lif - Series002.tif', 67: '1.2%_1Hour_Rab5.lif - Series003.tif', 68: '1.2%_1Hour_Rab5.lif - Series004.tif', 69: '1.2%_1Hour_Rab5.lif - Series005.tif', 70: '1.2%_1Hour_Rab5.lif - Series006.tif', 71: '1.2%_1Hour_Rab7.lif - Series001.tif', 72: '1.2%_1Hour_Rab7.lif - Series004.tif', 73: '1.2%_1Hour_Rab7.lif - Series005.tif', 74: '1.2%_1Hour_Rab7.lif - Series006.tif', 75: '1.2%_1Hour_Rab7.lif - Series007.tif', 76: '1.2%_1Hour_Rab7.lif - Series008.tif', 77: '1.2%_1Hour_Syndapin 2.lif - Series001.tif', 78: '1.2%_1Hour_Syndapin 2.lif - Series002.tif', 79: '1.2%_1Hour_Syndapin 2.lif - Series003.tif', 80: '1.2%_1Hour_Syndapin 2.lif - Series004.tif', 81: '1.2%_1Hour_Syndapin 2.lif - Series005.tif', 82: '1.2%_1Hour_Syndapin 2.lif - Series006.tif', 83: '1.2%_2Hours_A-Tubulin.lif - Series001.tif', 84: '1.2%_2Hours_A-Tubulin.lif - Series002.tif', 85: '1.2%_2Hours_A-Tubulin.lif - Series003.tif', 86: '1.2%_2Hours_A-Tubulin.lif - Series004.tif', 87: '1.2%_2Hours_A-Tubulin.lif - Series005.tif', 88: '1.2%_2Hours_B-Actin.lif - Series001.tif', 89: '1.2%_2Hours_B-Actin.lif - Series002.tif', 90: '1.2%_2Hours_B-Actin.lif - Series003.tif', 91: '1.2%_2Hours_B-Actin.lif - Series004.tif', 92: '1.2%_2Hours_B-Actin.lif - Series005.tif', 93: '1.2%_2Hours_B-Actin.lif - Series006.tif', 94: '1.2%_2Hours_Caveolin 1.lif - Series001.tif', 95: '1.2%_2Hours_Caveolin 1.lif - Series002.tif', 96: '1.2%_2Hours_Caveolin 1.lif - Series003.tif', 97: '1.2%_2Hours_Caveolin 1.lif - Series004.tif', 98: '1.2%_2Hours_Caveolin 1.lif - Series005.tif', 99: '1.2%_2Hours_Caveolin 1.lif - Series006.tif', 100: '1.2%_2Hours_Clathrin.lif - Series001.tif', 101: '1.2%_2Hours_Clathrin.lif - Series002.tif', 102: '1.2%_2Hours_Clathrin.lif - Series003.tif', 103: '1.2%_2Hours_Clathrin.lif - Series004.tif', 104: '1.2%_2Hours_Clathrin.lif - Series005.tif', 105: '1.2%_2Hours_Clathrin.lif - Series006.tif', 106: '1.2%_2Hours_LAMP-1.lif - Series001.tif', 107: '1.2%_2Hours_LAMP-1.lif - Series002.tif', 108: '1.2%_2Hours_LAMP-1.lif - Series003.tif', 109: '1.2%_2Hours_LAMP-1.lif - Series004.tif', 110: '1.2%_2Hours_LAMP-1.lif - Series005.tif', 111: '1.2%_2Hours_LAMP-1.lif - Series006.tif', 112: '1.2%_2Hours_Myosin.lif - Series001.tif', 113: '1.2%_2Hours_Myosin.lif - Series002.tif', 114: '1.2%_2Hours_Myosin.lif - Series003.tif', 115: '1.2%_2Hours_Myosin.lif - Series004.tif', 116: '1.2%_2Hours_Myosin.lif - Series005.tif', 117: '1.2%_2Hours_Myosin.lif - Series006.tif', 118: '1.2%_2Hours_Rab5.lif - Series001.tif', 119: '1.2%_2Hours_Rab5.lif - Series002.tif', 120: '1.2%_2Hours_Rab5.lif - Series003.tif', 121: '1.2%_2Hours_Rab5.lif - Series004.tif', 122: '1.2%_2Hours_Rab5.lif - Series005.tif', 123: '1.2%_2Hours_Rab5.lif - Series006.tif', 124: '1.2%_2Hours_Rab7.lif - Series001.tif', 125: '1.2%_2Hours_Rab7.lif - Series002.tif', 126: '1.2%_2Hours_Rab7.lif - Series003.tif', 127: '1.2%_2Hours_Rab7.lif - Series004.tif', 128: '1.2%_2Hours_Rab7.lif - Series005.tif', 129: '1.2%_2Hours_Rab7.lif - Series006.tif', 130: '6%_1Hour_Syndapin 2.lif - Series001.tif', 131: '6%_1Hour_Syndapin 2.lif - Series002.tif', 132: '6%_1Hour_Syndapin 2.lif - Series003.tif', 133: '6%_1Hour_Syndapin 2.lif - Series004.tif', 134: '6%_1Hour_Syndapin 2.lif - Series005.tif', 135: '6%_1Hour_Syndapin 2.lif - Series006.tif', 136: '6.0%_2Hours_A-Tubulin.lif - Series001.tif', 137: '6.0%_2Hours_A-Tubulin.lif - Series002.tif', 138: '6.0%_2Hours_A-Tubulin.lif - Series003.tif', 139: '6.0%_2Hours_A-Tubulin.lif - Series004.tif', 140: '6.0%_2Hours_A-Tubulin.lif - Series005.tif', 141: '6.0%_2Hours_A-Tubulin.lif - Series006.tif', 142: '6.0%_2Hours_B-Actin.lif - Series001.tif', 143: '6.0%_2Hours_B-Actin.lif - Series002.tif', 144: '6.0%_2Hours_B-Actin.lif - Series003.tif', 145: '6.0%_2Hours_B-Actin.lif - Series004.tif', 146: '6.0%_2Hours_B-Actin.lif - Series005.tif', 147: '6.0%_2Hours_B-Actin.lif - Series006.tif', 148: '6%_2Hours_Caveolin 1.lif - Series001.tif', 149: '6%_2Hours_Caveolin 1.lif - Series002.tif', 150: '6%_2Hours_Caveolin 1.lif - Series003.tif', 151: '6%_2Hours_Caveolin 1.lif - Series004.tif', 152: '6%_2Hours_Caveolin 1.lif - Series005.tif', 153: '6%_2Hours_Caveolin 1.lif - Series006.tif', 154: '6.0%_2Hours_Clathrin.lif - Series001.tif', 155: '6.0%_2Hours_Clathrin.lif - Series002.tif', 156: '6.0%_2Hours_Clathrin.lif - Series003.tif', 157: '6.0%_2Hours_Clathrin.lif - Series004.tif', 158: '6.0%_2Hours_Clathrin.lif - Series005.tif', 159: '6.0%_2Hours_Clathrin.lif - Series006.tif', 160: '6.0%_2Hours_Dynamin.lif - Series001.tif', 161: '6.0%_2Hours_Dynamin.lif - Series002.tif', 162: '6.0%_2Hours_Dynamin.lif - Series003.tif', 163: '6.0%_2Hours_Dynamin.lif - Series004.tif', 164: '6.0%_2Hours_Dynamin.lif - Series005.tif', 165: '6.0%_2Hours_Dynamin.lif - Series006.tif', 166: '6.0%_2Hours_Dynein.lif - Series001.tif', 167: '6.0%_2Hours_Dynein.lif - Series002.tif', 168: '6.0%_2Hours_Dynein.lif - Series003.tif', 169: '6.0%_2Hours_Dynein.lif - Series004.tif', 170: '6.0%_2Hours_Dynein.lif - Series005.tif', 171: '6.0%_2Hours_Dynein.lif - Series006.tif', 172: 'Negative Control.lif - Series001.tif', 173: 'Negative Control.lif - Series002.tif', 174: 'Negative Control.lif - Series003.tif', 175: 'Negative Control.lif - Series004.tif', 176: 'Negative Control.lif - Series006.tif', 177: 'Negative Control.lif - Series007.tif'}\n"
     ]
    }
   ],
   "source": [
    "ID=0\n",
    "ID_dir={}\n",
    "for id_ in test_ids:\n",
    "    path = TEST_PATH + id_+'/images/'\n",
    "    dir_3=os.listdir(path)\n",
    "    k=len(dir_3)\n",
    "    for i in range(0,k): \n",
    "        ID_dir[ID]=dir_3[i]\n",
    "        ID+=1\n",
    "print(ID_dir)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b8e5c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "for i in range(0,len(X_test)):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(X_test[i])\n",
    "    #plt.title('original test')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(preds_test_t[i])\n",
    "    #plt.title('Predictions')\n",
    "    plt.axis('off')\n",
    "    #plt.subplot(313)\n",
    "    #plt.imshow(np.squeeze(preds_test_t[i]))\n",
    "    #plt.plt.title('Threshold predictions')\n",
    "    #plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    figure_save_path ='pred_set/'\n",
    "    if not os.path.exists(figure_save_path):# if directory not exist, create it\n",
    "        os.makedirs(figure_save_path)   \n",
    "    plt.savefig(os.path.join(figure_save_path , '{}'.format(ID_dir[i])),bbox_inches='tight', pad_inches = -0.1)\n",
    "    plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f218a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an initial image with two overlapping circles\n",
    "x, y = np.indices((80, 80))\n",
    "x1, y1, x2, y2 = 28, 28, 44, 52\n",
    "r1, r2 = 16, 20\n",
    "mask_circle1 = (x - x1)**2 + (y - y1)**2 < r1**2\n",
    "mask_circle2 = (x - x2)**2 + (y - y2)**2 < r2**2\n",
    "image = np.logical_or(mask_circle1, mask_circle2)\n",
    "\n",
    "# Now we want to separate the two objects in image\n",
    "# Generate the markers as local maxima of the distance to the background\n",
    "distance = ndi.distance_transform_edt(image)\n",
    "coords = peak_local_max(distance, footprint=np.ones((3, 3)), labels=image)\n",
    "mask = np.zeros(distance.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "markers, _ = ndi.label(mask)\n",
    "labels = watershed(-distance, markers, mask=image)\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Overlapping objects')\n",
    "ax[1].imshow(-distance, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Distances')\n",
    "ax[2].imshow(labels, cmap=plt.cm.nipy_spectral)\n",
    "ax[2].set_title('Separated objects')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
