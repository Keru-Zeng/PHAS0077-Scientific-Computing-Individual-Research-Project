{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd146f8",
   "metadata": {},
   "source": [
    "test the build-in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c37c12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful libraries\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb\n",
    "from functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b8e5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10 # the higher the better\n",
    "IMG_WIDTH = 128 # for faster computing on kaggle\n",
    "IMG_HEIGHT = 128 # for faster computing on kaggle\n",
    "IMG_CHANNELS = 3 \n",
    "TEST_PATH='./test_set/'# our project\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "n_num=num(dirname='tifs - unanalysed/')\n",
    "#build our test set\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "X_test = np.zeros((n_num, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "#just to ensure that len of X_test is equal to len of sizes_test\n",
    "sizes_test = []\n",
    "sys.stdout.flush()\n",
    "n=0\n",
    "for id_ in tqdm(test_ids, total=len(test_ids)):\n",
    "    path = TEST_PATH + id_+'/images/'\n",
    "    dir_3=os.listdir(path)\n",
    "    k=len(dir_3)\n",
    "    for i in range(0,k): \n",
    "        img = imread(path +dir_3[i])[:,:,:IMG_CHANNELS] # look for all pictures with name Series001\n",
    "        sizes_test.append([img.shape[0], img.shape[1]])# append sizes of figures i.e. 256*256 pixel: [256,256]\n",
    "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "        X_test[n]=img\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a82bb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:23<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "#modified from https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_label.html\n",
    "for id_ in tqdm(test_ids, total=len(test_ids)):\n",
    "    path = TEST_PATH + id_+'/images/'\n",
    "    dir_3=os.listdir(path)\n",
    "    k=len(dir_3)\n",
    "    for i in range(0,k):   \n",
    "        image = imread(path +dir_3[i])[:,:,:3]# load the pictures\n",
    "        image = rgb2gray(image) #convert to greyscale after loading\n",
    "        thresh = threshold_otsu(image) # perform automatic thresholding\n",
    "        bw = closing(image >thresh,square(3)) #convert 0，1 to bool\n",
    "        # remove artifacts connected to image border\n",
    "        cleared = clear_border(bw)\n",
    "        # label image regions\n",
    "        label_image = label(cleared)\n",
    "        # to make the background transparent, pass the value of `bg_label`,\n",
    "        # and leave `bg_color` as `None` and `kind` as `overlay`\n",
    "        image_label_overlay = label2rgb(label_image, image=image, bg_label=0)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.imshow(image_label_overlay)\n",
    "        for region in regionprops(label_image):\n",
    "            # take regions with large enough areas\n",
    "            if region.area >= 150:\n",
    "                # draw rectangle around segmented coins\n",
    "                minr, minc, maxr, maxc = region.bbox\n",
    "                rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr, fill=False, edgecolor='red', linewidth=2)\n",
    "                ax.add_patch(rect)\n",
    "        ax.set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        figure_save_path ='label_set/'+id_\n",
    "        if not os.path.exists(figure_save_path):# if directory not exist, create it\n",
    "            os.makedirs(figure_save_path)   \n",
    "        plt.savefig(os.path.join(figure_save_path , '{}'.format(dir_3[i])),bbox_inches='tight', pad_inches = -0.1)\n",
    "        plt.close()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe6ce7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 450ms/step\n"
     ]
    }
   ],
   "source": [
    "#load the model and use it to make predicted results\n",
    "model = load_model('model.h5', custom_objects={'accuracy': 'accuracy'})\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "#Threshold predictions\n",
    "preds_test_t = (preds_test > 0.8).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a48aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=0\n",
    "ID_dir={}\n",
    "for id_ in test_ids:\n",
    "    path = TEST_PATH + id_+'/images/'\n",
    "    dir_3=os.listdir(path)\n",
    "    k=len(dir_3)\n",
    "    for i in range(0,k): \n",
    "        ID_dir[ID]=dir_3[i]\n",
    "        ID+=1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eed8f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "for i in range(0,len(X_test)):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(preds_test_t[i])\n",
    "    #plt.title('Predictions')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    figure_save_path ='pred_set/'\n",
    "    if not os.path.exists(figure_save_path):# if directory not exist, create it\n",
    "        os.makedirs(figure_save_path)   \n",
    "    plt.savefig(os.path.join(figure_save_path , '{}'.format(ID_dir[i])),bbox_inches='tight', pad_inches = -0.1)\n",
    "    plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f218a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b288a3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZKR\\Desktop\\PHAS0077-Scientific-Computing-Individual-Research-Project\\functions.py:199: FutureWarning: indices argument is deprecated and will be removed in version 0.20. To avoid this warning, please do not use the indices argument. Please see peak_local_max documentation for more details.\n",
      "  localMax = peak_local_max(D, indices=False, min_distance=50, labels=thresh)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: 16 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 23 unique segments found\n",
      "Note: 12 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 12 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 12 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 22 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 23 unique segments found\n",
      "Note: 11 unique segments found\n",
      "Note: 22 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 26 unique segments found\n",
      "Note: 27 unique segments found\n",
      "Note: 30 unique segments found\n",
      "Note: 24 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 0 unique segments found\n",
      "Note: 0 unique segments found\n",
      "Note: 3 unique segments found\n",
      "Note: 2 unique segments found\n",
      "Note: 0 unique segments found\n",
      "Note: 3 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 12 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 12 unique segments found\n",
      "Note: 11 unique segments found\n",
      "Note: 12 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 25 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 21 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 22 unique segments found\n",
      "Note: 21 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 12 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 11 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 21 unique segments found\n",
      "Note: 12 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 10 unique segments found\n",
      "Note: 21 unique segments found\n",
      "Note: 30 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 24 unique segments found\n",
      "Note: 25 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 12 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 25 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 29 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 21 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 22 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 23 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 25 unique segments found\n",
      "Note: 23 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 24 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 31 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 25 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 23 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 21 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 9 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 10 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 22 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 23 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 25 unique segments found\n",
      "Note: 21 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 21 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 23 unique segments found\n",
      "Note: 23 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 10 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 22 unique segments found\n",
      "Note: 10 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 9 unique segments found\n",
      "Note: 25 unique segments found\n",
      "Note: 9 unique segments found\n",
      "Note: 24 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 27 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 13 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 15 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 20 unique segments found\n",
      "Note: 14 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 17 unique segments found\n",
      "Note: 19 unique segments found\n",
      "Note: 16 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 18 unique segments found\n",
      "Note: 14 unique segments found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = './pred_set/'\n",
    "dirs=os.listdir(path)\n",
    "kk=len(dirs)\n",
    "for i in range(0,kk):\n",
    "    name=path+str(dirs[i])\n",
    "    sep_count_cells(filename=name)\n",
    "    figure_save_path ='sep_set/'\n",
    "    if not os.path.exists(figure_save_path):# if directory not exist, create it\n",
    "        os.makedirs(figure_save_path)   \n",
    "    plt.savefig(os.path.join(figure_save_path , '{}'.format(dirs[i])),bbox_inches='tight', pad_inches = -0.1)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f64218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
